{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.modules())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(out.detach().numpy()), np.min(out.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "plt.bar(range(1000), out.detach().numpy().reshape(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from KD_Lib.models.resnet import ResNet18, ResNet50, ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cfg:\n",
    "    def __init__(self, dict=None):\n",
    "        if dict is not None:\n",
    "            for key in dict:\n",
    "                setattr(self, key, dict[key])\n",
    "            return\n",
    "        \n",
    "        self.MODE: str = 'shake' # 'kd' or 'dml' or 'shake'\n",
    "        self.DATASET: str = 'cifar100' # 'cifar10' or 'cifar100'\n",
    "        self.CLASSES: int = 100\n",
    "        self.DATA_PATH: str = '../Knowledge-Distillation-Zoo/datasets/'\n",
    "        self.BATCH_SIZE: int = 128\n",
    "        self.TEACHER = 'resnet152' \n",
    "        self.STUDENT = 'resnet18'\n",
    "        self.LR: float = 0.1\n",
    "        self.LR_MIN: float = 1e-6 #1e-5\n",
    "        self.T: float = 1.0\n",
    "        self.W: float = 0.5\n",
    "        self.EPOCHS: int = 200\n",
    "        self.SCHEDULER: str = 'cos' # 'cos' or 'step'\n",
    "        self.TEACHER_WEIGHTS: str = f'./models/teacher_{self.DATASET}_{self.MODE}.pt'\n",
    "        self.PARALLEL: bool = False\n",
    "        self.EXP: str = f\"{self.MODE}_{self.DATASET}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Cfg()\n",
    "cfg.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cfg.json\", \"w\") as file:\n",
    "    json.dump(cfg.__dict__, file)\n",
    " \n",
    "with open(\"cfg.json\", \"r\") as file:\n",
    "    loaded_cfg = json.load(file)\n",
    " \n",
    "print(loaded_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Cfg(loaded_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, MultiStepLR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 200\n",
    "LR = 0.1\n",
    "ETA = 1e-5\n",
    "\n",
    "lrs = []\n",
    "optimizer = torch.optim.SGD([torch.tensor(1)], lr=LR)\n",
    "scheduler = CosineAnnealingLR(optimizer, STEPS, eta_min=ETA, last_epoch=-1)\n",
    "for _ in range(STEPS):\n",
    "    optimizer.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "plt.plot(lrs, label=scheduler.__class__.__name__)\n",
    "\n",
    "lrs = []\n",
    "optimizer = torch.optim.SGD([torch.tensor(1)], lr=LR)\n",
    "scheduler = LinearLR(optimizer, total_iters=STEPS, start_factor=1, end_factor=ETA/LR)\n",
    "for _ in range(STEPS):\n",
    "    optimizer.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "plt.plot(lrs, label=scheduler.__class__.__name__)\n",
    "\n",
    "lrs = []\n",
    "optimizer = torch.optim.SGD([torch.tensor(1)], lr=LR)\n",
    "scheduler = MultiStepLR(optimizer, [60, 120, 180], gamma=0.1)\n",
    "for _ in range(STEPS):\n",
    "    optimizer.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "plt.plot(lrs, label=scheduler.__class__.__name__)\n",
    "\n",
    "#plt.semilogy()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUB200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from KD_Lib.datasets import Cub200\n",
    "\n",
    "DATASET = 'cub200'\n",
    "DATA_PATH = '../Knowledge-Distillation-Zoo/datasets/'\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'cifar100':\n",
    "    dataset = datasets.CIFAR100\n",
    "    mean = (0.5071, 0.4865, 0.4409)\n",
    "    std  = (0.2673, 0.2564, 0.2762)\n",
    "    imsize = 32\n",
    "elif DATASET == 'cub200':\n",
    "    dataset = Cub200\n",
    "    mean = (104/255.0, 117/255.0, 128/255.0)\n",
    "    std = (1/255.0, 1/255.0, 1/255.0)\n",
    "    imsize = 227\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(imsize, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "trainset = dataset(root=DATA_PATH, train=True, download=False, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18 as ResNet18, resnet50 as ResNet50, resnet152 as ResNet152\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(weights=None, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KD_Lib.models.resnet import ResNet18, ResNet50, ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = ResNet18(num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model_new.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_n_params(model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from KD_Lib.models.resnet_torch import get_ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_ResNet('resnet18', 10).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn(1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(test, norm_feats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hist(model.forward(test, norm_feats=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, feats, weight, bias = model.forward(torch.randn(2, 3, 32, 32), return_feats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = './exp/'\n",
    "\n",
    "experiments = []\n",
    "for dirname, _, filenames in os.walk(DIR):\n",
    "    for filename in filenames:\n",
    "        experiments.append(json.load(open(os.path.join(dirname, filename), 'r')))\n",
    "\n",
    "df = pd.DataFrame(experiments)\n",
    "T = df[df['EXP'] == 'kd_cifar100_new'].iloc[0]['TIME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRD\n",
    "T_KD = 109.26\n",
    "T_CRD = 156.58\n",
    "T_CRD / T_KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['T_LAST'] = df['VACC'].apply(lambda x: x['T_LAST'])\n",
    "df['T_BEST'] = df['VACC'].apply(lambda x: x['T_BEST'])\n",
    "df['S_LAST'] = df['VACC'].apply(lambda x: x['S_LAST'])\n",
    "df['S_BEST'] = df['VACC'].apply(lambda x: x['S_BEST'])\n",
    "df['TIME'] = df['TIME'].apply(lambda x: x/T)\n",
    "df[['EXP', 'T', 'W', 'FEAT_NORM', 'T_LAST', 'T_BEST', 'S_LAST', 'S_BEST', 'TIME']].sort_values(by='S_BEST', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from KD_Lib.models import model_dict\n",
    "from KD_Lib.models.resnet_torch import monkey_patch\n",
    "from KD_Lib.models.resnet import BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher: 1.7e+06 params\n",
      "Student: 2.8e+05 params\n"
     ]
    }
   ],
   "source": [
    "teacher = model_dict['resnet110'](num_classes=100)\n",
    "student = monkey_patch(teacher, custom=True)\n",
    "pytorch_total_params = sum(p.numel() for p in teacher.parameters())\n",
    "print(f\"Teacher: {pytorch_total_params:.1e} params\")\n",
    "teacher.load_state_dict(torch.load('./models/resnet110_cifar100.pt'))\n",
    "\n",
    "student = model_dict['resnet20'](num_classes=100)\n",
    "student = monkey_patch(student, custom=True)\n",
    "pytorch_total_params = sum(p.numel() for p in student.parameters())\n",
    "print(f\"Student: {pytorch_total_params:.1e} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teacher.layer1), len(student.layer1) # 18/3 per layer -> copy 1/6 of the blocks\n",
    "len(teacher.layer2), len(student.layer2) # 18/3 per layer -> copy 1/6 of the blocks\n",
    "len(teacher.layer3), len(student.layer3) # 18/3 per layer -> copy 1/6 of the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [(0,0),(1,9),(2,17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lt, ls in zip(teacher.children(), student.children()):\n",
    "    # print(type(lt), type(ls))\n",
    "    if isinstance(lt, torch.nn.Sequential):\n",
    "        for s, t in blocks:\n",
    "            # print(type(lt[t]), type(ls[s]))\n",
    "            ls[s].load_state_dict(lt[t].state_dict())\n",
    "    else:\n",
    "        ls.load_state_dict(lt.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), './models/resnet20_cifar100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KD_Lib.models.resnet_test import ResNet50\n",
    "from KD_Lib.models.shake import ShakeHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Parameters: {pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(2, 3, 224, 224)\n",
    "feat_t, out_t = model(data, is_feat=True)\n",
    "shake = ShakeHead(feat_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in shake.parameters())\n",
    "print(f\"Parameters: {pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.randint(0, 10, (1,))\n",
    "pred_t, pred_f = torch.zeros(10), torch.zeros(10)\n",
    "pred_t[label] = 0.8\n",
    "pred_t += 0.2 / 10\n",
    "pred_f[torch.randint(0, 10, (1,))] = 0.8\n",
    "pred_f += 0.2 / 10\n",
    "pred_t_s = torch.softmax(pred_t/4, dim=-1)\n",
    "pred_f_s = torch.softmax(pred_f/4, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_t, pred_f, pred_t_s, pred_f_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.cross_entropy(pred_t.unsqueeze(0), label), torch.nn.functional.cross_entropy(pred_f.unsqueeze(0), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.cross_entropy(pred_t_s.unsqueeze(0), label), torch.nn.functional.cross_entropy(pred_f_s.unsqueeze(0), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HP Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "import optuna\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = None\n",
    "file = './hp_search/hp_search_240126111134.pkl' # old\n",
    "#file = '../ray_results/hp_search_240127091935/searcher-state-2024-01-27_09-19-39.pkl' # new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file is not None:\n",
    "    try:\n",
    "        study = joblib.load(file)['_ot_study']\n",
    "    except:\n",
    "        study = joblib.load(file)\n",
    "    print(f\"Best trial until now ({len(study.trials)} trials):\")\n",
    "    print(\" Value: \", study.best_trial.value)\n",
    "    print(\" Params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    path = './hp_search/'\n",
    "    studies = [joblib.load(path+f) for f in os.listdir(path) \n",
    "            if os.path.isfile(os.path.join(path, f)) \n",
    "            and f.endswith('.pkl')]\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    for s in studies:\n",
    "        study.add_trials(s.get_trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe()[['number', 'datetime_start', 'value', 'params_Lc', 'params_Ld', 'params_Le', 'params_Lf']]\n",
    "df.sort_values(by='value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_intermediate_values(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jocor Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 240\n",
    "GRADUAL = 150\n",
    "FORGET_RATE = 0.1\n",
    "\n",
    "forget_scheduler = np.zeros(EPOCHS)\n",
    "forget_scheduler[:GRADUAL] = np.linspace(FORGET_RATE, 0, GRADUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(forget_scheduler)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kld = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "kld_test = torch.nn.KLDivLoss(reduction='none')\n",
    "mse = torch.nn.MSELoss(reduction='mean')\n",
    "mse_test = torch.nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[0.1, 0.2, 0.7], [0.3, 0.2, 0.5]])\n",
    "s = torch.tensor([[0.3, 0.2, 0.5], [0.1, 0.2, 0.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = kld(s.log(), t)\n",
    "loss_test = kld_test(s.log(), t).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mse(s, t)\n",
    "loss_test = mse_test(s, t).mean(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loralib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loralib.Linear(64, 100, 16)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Parameters: {pytorch_total_params}\")\n",
    "\n",
    "model = torch.nn.Linear(64, 100)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Parameters: {pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd = np.array([[71.99, 72.00], [71.36, 71.72], [71.32, 71.50]])\n",
    "shake = np.array([[71.15, 71.60], [71.62, 71.93], [71.18, 71.44], [71.73, 71.89]])\n",
    "smooth = np.array([[71.48, 71.81], [71.90, 71.91], [71.23, 71.43], [71.19, 71.34]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71.55666667 71.74      ] [71.42  71.715] [71.45   71.6225]\n",
      "[0.30684777 0.20461346] [0.25816661 0.20353132] [0.28257742 0.24221633]\n"
     ]
    }
   ],
   "source": [
    "print(kd.mean(axis=0), shake.mean(axis=0), smooth.mean(axis=0))\n",
    "print(kd.std(axis=0), shake.std(axis=0), smooth.std(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
